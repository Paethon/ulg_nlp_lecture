{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091d6b9-14c3-4e11-a0ef-ce55beeb4a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using OpenAI\n",
    "using JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01868ff1-b6d9-4d77-8391-b53b99447bf3",
   "metadata": {},
   "source": [
    "Useful links:\n",
    "- [Chat API Reference](https://platform.openai.com/docs/api-reference/chat)\n",
    "- [Julia Package Documentation](https://juliaml.github.io/OpenAI.jl/dev/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a2893-b796-45e9-bae8-538baf6fa83d",
   "metadata": {},
   "source": [
    "## Setting up the System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28bace-c5c9-46c7-8ad7-2604400866ed",
   "metadata": {},
   "source": [
    "The API key authenticates you to the API of OpenAI. If you have an account at OpenAI, you can generate such a key [here](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b99d2d-de05-4b86-bf10-06ae86d6ed16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = \"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1f068-e037-4718-a80c-421f59635df0",
   "metadata": {},
   "source": [
    "The model tells the system which specific model you want to use to produce the response. For the chat interface, `gpt-3.5-turbo` and `gpt-4` is available.\n",
    "\n",
    "My account has access to GPT-4, so feel free to try it out.\n",
    "\n",
    "Differences:\n",
    "- `gpt-3.5-turbo`\n",
    "  - Much faster\n",
    "  - Cheap\n",
    "- `gpt-4`\n",
    "  - Much more capable\n",
    "  - Much easier to prompt\n",
    "  - Slower\n",
    "  - ~30x more expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f6c5c-e290-472c-aa80-ed305a0e2214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5f0a1-ee1d-4c24-b748-d6fee90ca6ab",
   "metadata": {},
   "source": [
    "## Our first interaction with the System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9d9d8-67c9-4efa-966f-c138282ae921",
   "metadata": {},
   "source": [
    "Creating the messages to be sent to the system:\n",
    "\n",
    "Messages are a `Vector` of `Dicts`, describing the whole chat history up to this point. Note: The system does not remember anything! You have to send the whole history of your conversation with every request! \n",
    "\n",
    "Each entry in messages is a `Dict` of the form `\"role\" => string, \"content\" => string`, where `\"role\"` can be `\"system\"`, `\"user\"`, or `\"assistant\"` and `content` is a String.\n",
    "- `\"user\"` and `\"assistant\"` are used to tell the system what the user said and what the systems response was in previous steps of the chat\n",
    "- `\"system\"` can be the first entry in the messages and tells the system what it is and how it behaves. If it is left out, the system just behaves like a normal chat assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a65cb-b656-4d8e-b5a8-d9ff890beb86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    Dict(\"role\" => \"user\", \"content\" => \"When was Abraham Licoln born?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcec05-09d2-4c3f-a0f3-9cb98cae9b32",
   "metadata": {},
   "source": [
    "Now we can send our message to the chat-system also passing along our key and which model we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943adef-55f1-4f65-9089-90781733980d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = create_chat(api_key, model, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c511fc1-93a1-495b-9f29-21972db35456",
   "metadata": {},
   "source": [
    "Let's get the actual response of the assistant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea8bee-b0e7-421d-9577-5bb2fa8e2af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r.response[\"choices\"][1][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132caff-17f7-466b-ae5c-4897f316f665",
   "metadata": {},
   "source": [
    "## We can take the response and continue the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38969a29-8eb2-4581-8360-7113a5db7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    Dict(\"role\" => \"user\", \"content\" => \"When was Abraham Licoln born?\"),\n",
    "    Dict(\"role\" => \"assistant\", \"content\" => \"Abraham Lincoln was born on February 12, 1809.\"),\n",
    "    Dict(\"role\" => \"user\", \"content\" => \"When was he assasinated?\"),\n",
    "]\n",
    "r = create_chat(api_key, model, messages)\n",
    "r.response[\"choices\"][1][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb86a2f-c600-4f98-9e2a-99d547a8d448",
   "metadata": {},
   "source": [
    "## What about the system prompt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0afc3e2-19e7-4793-b933-28725a553b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    Dict(\"role\" => \"system\", \n",
    "        \"content\" => \"You are a chat system in opposite world named Marv that constantly lies and always gives absurd, hilariously wrong information\"),\n",
    "    Dict(\"role\" => \"user\", \n",
    "        \"content\" => \"Who was Abraham Licoln?\"),\n",
    "]\n",
    "r = create_chat(api_key, model, messages)\n",
    "r.response[\"choices\"][1][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5597a3-d9b6-4991-9b8c-0c75b82408a9",
   "metadata": {},
   "source": [
    "## Make it easier to use for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf8d3e-2dcd-4540-8869-8aa523cec47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_message(role, message) = Dict(\"role\" => role, \"content\" => message)\n",
    "\n",
    "function get_chat_response(\n",
    "        api_key::AbstractString, \n",
    "        model::AbstractString,\n",
    "        system_prompt::AbstractString,\n",
    "        prompt::AbstractString;\n",
    "        kwargs...\n",
    "        )::AbstractString\n",
    "    \n",
    "    messages = [\n",
    "        gen_message(\"system\", system_prompt),\n",
    "        gen_message(\"user\", prompt)\n",
    "    ]\n",
    "    \n",
    "    r = create_chat(api_key, model, messages; kwargs...)\n",
    "    \n",
    "    first(r.response[\"choices\"])[\"message\"][\"content\"]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817e3b8-fc2f-4813-99ec-d7014b884480",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_chat_response(\n",
    "    api_key,\n",
    "    model,\n",
    "    \"You are a very boring chat system that returns the number 42, no matter what the user inputs. Only return the number 42 as a response to every request!\",\n",
    "    \"Hello, how are you doing?\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d321d9-a354-4a90-a0f6-23e09dd39a82",
   "metadata": {},
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b86f20-4511-409f-8f4f-21d57decf7d6",
   "metadata": {},
   "source": [
    "What can we do with this now? Whatever you can dream up! The biggest problem is to come up with ideas and to convince the system to actually do what you want ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd1507-f593-4818-a838-f6f41fd8b97b",
   "metadata": {},
   "source": [
    "### A translation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa5c3c-3f31-40e0-8fc8-7360e9442cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "function translate(api_key, text, language; model = \"gpt-3.5-turbo\")\n",
    "    system_prompt = \"You are now a very reliable translation system. Whatever text you are given, translate it into $language while \n",
    "    preserving the meaning and the structure of the text as much as possible. Don't translate words and IT jargon that is usually not translated. Only output the translated text!\"\n",
    "    translation = get_chat_response(api_key, model, system_prompt, text)\n",
    "    translation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89cd639-932a-4161-93a8-06b79dc9a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(api_key, \"We are here at a lecture for the data science ULG at the university of Innsbruck\", \"German\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c850a6aa-46eb-4548-8b5f-69947663cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "program = \"\"\"\n",
    "def my_sum(values, threshold):\n",
    "    sum = values[0]\n",
    "    for v in values[1:]:\n",
    "        if v > threshold:\n",
    "            sum += v\n",
    "    return sum\n",
    "\"\"\"\n",
    "println(translate(api_key, program, \"julia\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbcefa1-13f2-4253-9a19-cbffdd021777",
   "metadata": {},
   "source": [
    "## More useful stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42f23f-180d-42bc-9702-384d6747540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function extract_first_json_object_regex(s::String)\n",
    "    pattern = r\"\\{(?:[^{}]|(?R))*\\}\"\n",
    "    m = match(pattern, s)\n",
    "\n",
    "    if m === nothing\n",
    "        error(\"No JSON object found in the input string.\")\n",
    "    end\n",
    "\n",
    "    json_str = m.match\n",
    "    return JSON.parse(json_str)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2af0c7-0397-4e0c-9019-97ccbb0ab083",
   "metadata": {},
   "source": [
    "### Name Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d0688-e723-4574-90d4-743d59ed85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "\"You are now a name extraction system. \n",
    "Given a text, extract all names of persons in the text and return them as a list in a JSON object under the key \"names\". \n",
    "ONLY output the JSON object and nothing else!\n",
    "\n",
    "Examples:\n",
    "Input:\n",
    "\"This is Joe Miller speaking. Could I please be connected to Henrietta?\n",
    "Output:\n",
    "{\"names\": [\"Joe Miller\", \"Henrietta\"]}\n",
    "\"\"\"\n",
    "res = get_chat_response(api_key, model, system_prompt,\n",
    "    \"Hello Sebastian, I am Marc and I am happy to meet you. I got your contact information from Sue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2a09d-9ef0-48a8-aa01-234bbb679c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = extract_first_json_object_regex(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e646ddc-8f09-4ed7-86af-ef044ec7e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1019fbde-5136-45d6-801f-db1c8e1a537e",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd94773-409c-4a9b-a855-1c52aa40714c",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f15d075-d9e3-41b9-8d51-12335bee52fc",
   "metadata": {},
   "source": [
    "Write a function that takes a url to a web-page and returns a summary of that page in the form of bullet points. Display the bullet points in a nice way using [markdown](https://www.markdownguide.org/basic-syntax/) syntax.\n",
    "\n",
    "You can use the `get_plain_text` function to extract the text of a webpage. Warning: The method is not super stable and might not work on all websites!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c980c-eea6-46ff-a245-45daf1efd5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Markdown\n",
    "using Gumbo\n",
    "using Cascadia\n",
    "using AbstractTrees\n",
    "import Gumbo.text\n",
    "\n",
    "function my_text(cur_doc::HTMLDocument)\n",
    "    string_parts = []\n",
    "\n",
    "    for elem in PreOrderDFS(cur_doc.root) \n",
    "        isa(elem, HTMLText) || continue\n",
    "        push!(string_parts, Gumbo.text(elem))\n",
    "    end\n",
    "\n",
    "    return join(string_parts, \" \")\n",
    "end\n",
    "\n",
    "function get_plain_text(url::String)\n",
    "    # Fetch the website content\n",
    "    content = read(download(url), String)\n",
    "\n",
    "    # Parse the HTML\n",
    "    cur_doc = Gumbo.parsehtml(content)\n",
    "\n",
    "    return my_text(cur_doc)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7746868d-6710-4e91-848f-25cb73f05ac9",
   "metadata": {},
   "source": [
    "You can display text in markdown format in a nicely formatted way using `Markdown.parse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57056d1-125a-473b-8a05-d995f63f097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown.parse(\"\"\"\n",
    "    - One\n",
    "    - Two\n",
    "    - Three\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841b610-b3ee-4cf4-9f17-25f7e0bcc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "function summarize(api_key, model, url)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d95a5a-95bb-4996-9e61-18fa39b4c692",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7c5ab-c7c7-47d0-b666-1b5260f20267",
   "metadata": {},
   "source": [
    "**Write a general text classification system**\n",
    "- You should be able to supply a list of classes the system can choose from\n",
    "- The system can select exactly one of the given classes\n",
    "- Your function should return only the selected class as its only output\n",
    "\n",
    "Use this function to do: \n",
    "- Sentiment classification of restaurant reviews\n",
    "- Prioritization of customer emails\n",
    "Either look for examples on-line or come up with them yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aeb355-53dd-442d-bcd8-cf5e29b5721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function classify(api_key::AbstractString, model::AbstractString, text::AbstractString, classes::Vector)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965990eb-2383-4bba-b7a1-b5d1607294f0",
   "metadata": {},
   "source": [
    "## Exercise 3 (bonus)\n",
    "\n",
    "Write a system that automatically detects whether an email contains an appointment. If it does, return the date, time, location, and a short description of the appointment.\n",
    "\n",
    "In addition, automatically write a response email letting the other party know that the appointment has been registered and what information has been extracted.\n",
    "\n",
    "**Info:** This will require multiple calls to the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a89e44-f9c8-483d-9e44-a8598396b3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
